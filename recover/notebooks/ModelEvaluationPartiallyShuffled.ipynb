{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import importlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from recover.utils.utils import get_tensor_dataset\n",
    "import reservoir as rdl\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Methods to get different types of loaders\n",
    "#####################################\n",
    "\n",
    "\n",
    "def get_regular_valid_loader(trainer):\n",
    "    return trainer.valid_loader\n",
    "\n",
    "def get_test_loader(trainer):\n",
    "    test_dataset = get_tensor_dataset(trainer.data, trainer.test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Iterator over trainers for a given config\n",
    "#####################################\n",
    "\n",
    "\n",
    "def trainer_iterator(config_file, path_to_conf):\n",
    "    configuration = importlib.import_module(\"recover.config.\" + config_file).configuration\n",
    "\n",
    "    # Loop over all runs for this configuration\n",
    "    for run_dir in tqdm(os.listdir(os.path.join(path_to_conf, config_file))):\n",
    "        print(run_dir)\n",
    "        if run_dir.startswith('BasicTrainer'):\n",
    "\n",
    "            this_run_results = {}\n",
    "\n",
    "            # Load params for that run\n",
    "            with open(os.path.join(path_to_conf, config_file, run_dir, 'params.json')) as f:\n",
    "                params = json.load(f)\n",
    "\n",
    "            # Load configuration (can contain grid_search args)\n",
    "            this_run_config = deepcopy(configuration)\n",
    "\n",
    "            # Replace grid_search args by the actual parameter for that run\n",
    "            for key in this_run_config['trainer_config']:\n",
    "                if type(this_run_config['trainer_config'][key]) is dict \\\n",
    "                and 'grid_search' in this_run_config['trainer_config'][key].keys():\n",
    "                    \n",
    "                    # If grid search over python classes, we need to load them\n",
    "                    if type(params[key]) is str and params[key].startswith('<class'):\n",
    "                        class_to_load = params[key]\n",
    "                        class_to_load = class_to_load.split(\"'\")[1]\n",
    "                        class_to_load = class_to_load.rpartition('.')\n",
    "                        path_to_class = class_to_load[0]\n",
    "                        class_to_load_name = class_to_load[-1]\n",
    "                        params[key] = getattr(importlib.import_module(path_to_class), \n",
    "                                              class_to_load_name)\n",
    "                    this_run_config['trainer_config'][key] = params[key]\n",
    "                    this_run_results[key] = params[key]\n",
    "\n",
    "            # Load trainer\n",
    "            trainer = this_run_config[\"trainer\"](this_run_config[\"trainer_config\"])\n",
    "\n",
    "            # Find the checkpoint corresponding to the best epoch (always two checkpoints, \n",
    "            # corresponding to best and last epochs)\n",
    "            cpt = 0\n",
    "            checkpoint = None\n",
    "            for dir_check in os.listdir(os.path.join(path_to_conf, config_file, run_dir)):\n",
    "                if dir_check.startswith('checkpoint'):\n",
    "                    cpt += 1\n",
    "                    if checkpoint is None:\n",
    "                        checkpoint = dir_check\n",
    "                    else:\n",
    "                        if int(dir_check.split('_')[-1]) < int(checkpoint.split('_')[-1]):\n",
    "                            checkpoint = dir_check\n",
    "                            \n",
    "            if cpt == 2:\n",
    "                # Only yield trainer if 2 checkpoints have been saved (corresponding to best and last epochs)\n",
    "\n",
    "                # Load model\n",
    "                trainer.model.load_state_dict(torch.load(path_to_conf + config_file + \"/\" + \n",
    "                                                 run_dir + \"/\" + checkpoint + \"/model.pth\",\n",
    "                                                 map_location=torch.device('cpu')))\n",
    "                print(\"Loaded model from\", run_dir, checkpoint)\n",
    "                \n",
    "                yield trainer\n",
    "\n",
    "#####################################\n",
    "# Main evaluation method\n",
    "#####################################\n",
    "\n",
    "\n",
    "def evaluate_config(config_file, path_to_conf, get_eval_loader=get_regular_valid_loader):\n",
    "    all_results = pd.DataFrame()\n",
    "\n",
    "    for trainer in trainer_iterator(config_file, path_to_conf):\n",
    "        \n",
    "        this_run_results = {}\n",
    "\n",
    "        # Evaluate\n",
    "        eval_metrics, _ = trainer.eval_epoch(trainer.data, get_eval_loader(trainer), \n",
    "                                             trainer.model)\n",
    "\n",
    "        # Create dataframe for this run\n",
    "        print(\"this run results\", this_run_results)\n",
    "        print(\"eval metrics\", eval_metrics)\n",
    "\n",
    "        this_run_results = {**this_run_results, **eval_metrics}\n",
    "        this_run_results['prop_of_shuffled_drugs'] = trainer.config['prop_of_shuffled_drugs']\n",
    "        \n",
    "        for key in this_run_results.keys():\n",
    "            this_run_results[key] = [this_run_results[key]]\n",
    "\n",
    "        this_run_df = pd.DataFrame.from_dict(this_run_results)\n",
    "\n",
    "        all_results = pd.concat([all_results, this_run_df])\n",
    "\n",
    "    all_results.reset_index()\n",
    "        \n",
    "    return all_results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair level split (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:02<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.25\n",
      "R2 0.206 \\pm 0.014\n",
      "spearman 0.46 \\pm 0.036\n",
      "Shuffled proportion 0.0\n",
      "R2 0.24 \\pm 0.003\n",
      "spearman 0.464 \\pm 0.005\n",
      "Shuffled proportion 0.75\n",
      "R2 0.22 \\pm 0.016\n",
      "spearman 0.452 \\pm 0.026\n",
      "Shuffled proportion 1.0\n",
      "R2 0.258 \\pm 0.003\n",
      "spearman 0.48 \\pm 0.022\n",
      "Shuffled proportion 0.5\n",
      "R2 0.229 \\pm 0.018\n",
      "spearman 0.464 \\pm 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:02<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.25\n",
      "R2 0.319 \\pm 0.025\n",
      "spearman 0.484 \\pm 0.037\n",
      "Shuffled proportion 0.0\n",
      "R2 0.346 \\pm 0.051\n",
      "spearman 0.474 \\pm 0.021\n",
      "Shuffled proportion 0.75\n",
      "R2 0.323 \\pm 0.061\n",
      "spearman 0.452 \\pm 0.014\n",
      "Shuffled proportion 1.0\n",
      "R2 0.349 \\pm 0.047\n",
      "spearman 0.478 \\pm 0.02\n",
      "Shuffled proportion 0.5\n",
      "R2 0.337 \\pm 0.051\n",
      "spearman 0.461 \\pm 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_evaluation_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Level Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrixDrugLevelSplitTest\n",
    "\n",
    "def get_drug_split_test_loader(trainer):\n",
    "    \n",
    "    dl_split_data = DrugCombMatrixDrugLevelSplitTest(cell_line='MCF7',\n",
    "                                     fp_bits=1024,\n",
    "                                     fp_radius=2)\n",
    "    dl_split_data.data.ddi_edge_response = dl_split_data.data.ddi_edge_bliss_max\n",
    "    \n",
    "    test_idxs = range(len(dl_split_data.data.ddi_edge_response))\n",
    "    \n",
    "    test_dataset = get_tensor_dataset(dl_split_data.data, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:02<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.75\n",
      "R2 0.0 \\pm 0.0\n",
      "spearman 0.037 \\pm 0.05\n",
      "Shuffled proportion 0.25\n",
      "R2 0.018 \\pm 0.016\n",
      "spearman 0.096 \\pm 0.066\n",
      "Shuffled proportion 0.0\n",
      "R2 0.036 \\pm 0.004\n",
      "spearman 0.153 \\pm 0.01\n",
      "Shuffled proportion 0.5\n",
      "R2 0.01 \\pm 0.005\n",
      "spearman -0.024 \\pm 0.105\n",
      "Shuffled proportion 1.0\n",
      "R2 0.02 \\pm 0.029\n",
      "spearman -0.092 \\pm 0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_drug_level_split_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_drug_split_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.75\n",
      "R2 0.379 \\pm 0.188\n",
      "spearman 0.445 \\pm 0.087\n",
      "Shuffled proportion 0.25\n",
      "R2 0.376 \\pm 0.17\n",
      "spearman 0.446 \\pm 0.083\n",
      "Shuffled proportion 0.0\n",
      "R2 0.406 \\pm 0.155\n",
      "spearman 0.455 \\pm 0.064\n",
      "Shuffled proportion 0.5\n",
      "R2 0.398 \\pm 0.159\n",
      "spearman 0.452 \\pm 0.061\n",
      "Shuffled proportion 1.0\n",
      "R2 0.382 \\pm 0.171\n",
      "spearman 0.438 \\pm 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"model_drug_level_split_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hidden drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrixOneHiddenDrugSplitTest\n",
    "\n",
    "def get_one_hidden_drug_split_test_loader(trainer):\n",
    "    \n",
    "    ohd_split_data = DrugCombMatrixOneHiddenDrugSplitTest(cell_line='MCF7',\n",
    "                                     fp_bits=1024,\n",
    "                                     fp_radius=2)\n",
    "    ohd_split_data.data.ddi_edge_response = ohd_split_data.data.ddi_edge_bliss_max\n",
    "    \n",
    "    test_idxs = range(len(ohd_split_data.data.ddi_edge_response))\n",
    "    \n",
    "    test_dataset = get_tensor_dataset(ohd_split_data.data, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:14<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.75\n",
      "R2 0.109 \\pm 0.021\n",
      "spearman 0.257 \\pm 0.096\n",
      "Shuffled proportion 0.25\n",
      "R2 0.131 \\pm 0.015\n",
      "spearman 0.257 \\pm 0.02\n",
      "Shuffled proportion 0.5\n",
      "R2 0.095 \\pm 0.038\n",
      "spearman 0.201 \\pm 0.07\n",
      "Shuffled proportion 0.0\n",
      "R2 0.18 \\pm 0.023\n",
      "spearman 0.32 \\pm 0.016\n",
      "Shuffled proportion 1.0\n",
      "R2 0.1 \\pm 0.062\n",
      "spearman 0.255 \\pm 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"one_hidden_drug_split_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_one_hidden_drug_split_test_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:09<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled proportion 0.75\n",
      "R2 0.257 \\pm 0.067\n",
      "spearman 0.418 \\pm 0.024\n",
      "Shuffled proportion 0.25\n",
      "R2 0.277 \\pm 0.061\n",
      "spearman 0.427 \\pm 0.025\n",
      "Shuffled proportion 0.5\n",
      "R2 0.259 \\pm 0.064\n",
      "spearman 0.426 \\pm 0.022\n",
      "Shuffled proportion 0.0\n",
      "R2 0.308 \\pm 0.097\n",
      "spearman 0.459 \\pm 0.053\n",
      "Shuffled proportion 1.0\n",
      "R2 0.252 \\pm 0.061\n",
      "spearman 0.416 \\pm 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout # backup current stdout\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "all_results = evaluate_config(config_file=\"one_hidden_drug_split_partially_shuffled\", \n",
    "             path_to_conf=\"/Users/paul/PycharmProjects/NewReservoir/\"\n",
    "                              \"Recover/RayLogs/\",\n",
    "             get_eval_loader=get_regular_valid_loader)\n",
    "\n",
    "sys.stdout = old_stdout # reset old stdout\n",
    "\n",
    "\n",
    "for prop in all_results[\"prop_of_shuffled_drugs\"].unique():\n",
    "    prop_results = all_results[all_results[\"prop_of_shuffled_drugs\"] == prop]\n",
    "    print(\"Shuffled proportion\", prop)\n",
    "\n",
    "    print(\"R2\", round(prop_results['comb_r_squared'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['comb_r_squared'].std(),3))\n",
    "    print('spearman', round(prop_results['spearman'].mean(), 3), \"\\pm\", \n",
    "          round(prop_results['spearman'].std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
